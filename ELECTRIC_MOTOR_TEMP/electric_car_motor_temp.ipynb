{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best profile for electric car motor temperatures\n",
    "\n",
    "\n",
    "First things first, the imports and the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"pmsm_temperature_data.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Description\n",
    "\n",
    "Before we get to know our data better lets first clear what all this features mean:\n",
    "\n",
    "**ambient:** Ambient temperature as measured by a thermal sensor located closely to the stator.  \n",
    "**coolant:** Coolant temperature. The motor is water cooled. Measurement is taken at outflow.  \n",
    "**u_d:** Voltage d-component  \n",
    "**u_q:** Voltage q-component  \n",
    "**motor_speed:** Motor speed  \n",
    "**torque:** Torque induced by c urrent.  \n",
    "**i_d:** Current d-component  \n",
    "**i_q:** Current q-component  \n",
    "**pm:** Permanent Magnet surface temperature representing the rotor temperature. This was measured with an infrared thermography unit.  \n",
    "**stator_yoke:** Stator yoke temperature measured with a thermal sensor.  \n",
    "**stator_tooth:** Stator tooth temperature measured with a thermal sensor.  \n",
    "**stator_winding:** Stator winding temperature measured with a thermal sensor.  \n",
    "**profile_id:** Each measurement session has a unique ID. Make sure not to try to estimate from one session onto the other as they are  \n",
    "\n",
    "## Goal\n",
    "\n",
    "Get a overview of the coorelation of the data which features make sense to keep which are redundant/ have a lot na values. Final goal is it to find the best settings how our motor can be most energie efficient, lets see how far we can get!\n",
    "\n",
    "## Visual inspection\n",
    "\n",
    "\n",
    "### Histogram\n",
    "\n",
    "Probably one of the easiest visualisation, a histogram of the three *main* features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ambient\"].iplot(kind=\"histogram\", bins=1, theme=\"white\", title=\"ambient\",xTitle='ambient', yTitle='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"coolant\"].iplot(kind=\"histogram\", bins=1, theme=\"white\", title=\"coolant\",xTitle='coolant', yTitle='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"motor_speed\"].iplot(kind=\"histogram\", bins=1, theme=\"white\", title=\"motor_speed\",xTitle='motor_speed', yTitle='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the data do not appear to make a lot of sense to me, they might have been scaled using normalization, we can check that easy by using the build in pandas function *describe*, this will give us among other things the mean of the data which should be 0 and the standard deviation which should be somewhere 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what I expected, the mean of all values (except the profile_id) is zero, and the standard deviation (std in the table above) is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap\n",
    "\n",
    "Lets start with a simple heatmap, this will give us some first insights in the correlation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr().iplot(kind='heatmap',colorscale=\"blues\", title=\"Feature Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Distplot\n",
    "\n",
    "Next lets give a distplot a try, this gives us a deeper insights in the correlation between the single datapoints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "g = sns.pairplot(data, size=2.5)\n",
    "for i, j in zip(*np.triu_indices_from(g.axes, 1)):\n",
    "    g.axes[i, j].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data to have a mean of ~0 and a variance of 1\n",
    "X_std = StandardScaler().fit_transform(data)\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA(n_components=13)\n",
    "principalComponents = pca.fit_transform(X_std)\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(features)\n",
    "# Save components to a DataFrame\n",
    "PCA_components = pd.DataFrame(principalComponents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  see a big drop after the first **three features** and then again a smaller, but anyway bigger as normal, drop after **5** features, lets take make another check with another Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data_cluster = data\n",
    "n_cluster = range(1, 13)\n",
    "kmeans = [KMeans(n_clusters=i).fit(data_cluster) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data_cluster) for i in range(len(kmeans))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(n_cluster, scores)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *elbow point* which is the important point to look at is here as well at **three features**, interesting to see is that the difference from features 4 to 5 is not visible here the same as in the PCA analysis.\n",
    "\n",
    "Anyway, lets take a look at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(PCA_components[0], PCA_components[1], alpha=.05, color='black')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear structure is visible in 2 Dimensions, lets try three:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(PCA_components[0], PCA_components[1], PCA_components[2], alpha=.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No patterns as well... maybe a *4th dimension* will give us some clearness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = PCA_components[0]\n",
    "y = PCA_components[1]\n",
    "z = PCA_components[2]\n",
    "c = PCA_components[3]\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
